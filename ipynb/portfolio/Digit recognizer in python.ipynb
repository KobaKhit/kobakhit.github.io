{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer in Python using Convolutional Neural Nets\n",
    "\n",
    "by [Koba Khitalishvili](http://www.kobakhit.com/)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "I used Mathematica and a standard Neural Network model to get ~0.98 accuracy score after 40 minutes of computing. Starting with a brief benchmark Python code [found in the forums](https://www.kaggle.com/c/digit-recognizer/forums/t/2299/getting-started-python-sample-code-random-forest) one can jump into solving the Digit Recognizer\n",
    "problem right away. Below code that uses Random Forest algorithm to classify images as digits will give you \n",
    "around 0.96 accuracy score in less than a minute which is great. However, this score will put you lower than the 200th place. \n",
    "According to [MNIST web page](http://yann.lecun.com/exdb/mnist/), convolutional neural networks algorithm yields good results.\n",
    "I will try a simple neural network algorithm out in Python, expand it into a convolutional neural network and see if I can break into the top 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# create the training & test sets, skipping the header row with [1:]\n",
    "dataset = pd.read_csv(\"../mnist-data/train.csv\")\n",
    "target = dataset[[0]].values.ravel()\n",
    "train = dataset.iloc[:,1:].values\n",
    "test = pd.read_csv(\"../mnist-data/test.csv\").values\n",
    "\n",
    "# create and train the random forest\n",
    "# multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(train, target)\n",
    "pred = rf.predict(test)\n",
    "\n",
    "np.savetxt('submission_rand_forest.csv', \\\n",
    "           np.c_[range(1,len(test)+1),pred], delimiter=',', \\\n",
    "           header = 'ImageId,Label', comments = '', fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. Data Preprocessing\n",
    "2. Train, Predict and Save\n",
    "3. Conclusion\n",
    "\n",
    "## Data Preprocessing\n",
    "First, lets prepare the data. The `train.csv` has 42k rows. The first column is the digit labels. The rest 784 columns\n",
    "are pixel color values that go from 0 to 255. After loading in the csv files in code section above, I saved the digit labels in the `target` variable and rows of pixel color values  in the `train` variable. \n",
    "The `test.csv` contains 28k rows of just the pixel color values which we need to classify as digits. Here is the preview of the complete MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0       0    ...            0         0         0         0         0   \n",
      "1       0    ...            0         0         0         0         0   \n",
      "2       0    ...            0         0         0         0         0   \n",
      "3       0    ...            0         0         0         0         0   \n",
      "4       0    ...            0         0         0         0         0   \n",
      "\n",
      "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0         0  \n",
      "1         0         0         0         0         0  \n",
      "2         0         0         0         0         0  \n",
      "3         0         0         0         0         0  \n",
      "4         0         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I convert each data variable from a python list into a numpy array. For the `target` array I specify the integer data type.\n",
    "The train set has 42k rows and 784 columns, so its shape is `(42k,784)`. Each row is a 28 by 28 pixel\n",
    "picture. I will reshape the train set to have `(42k,1)` shape, i.e. each row will contain a 28 by 28 matrix of pixel color values. Same for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to array, specify data type, and reshape\n",
    "target = target.astype(np.uint8)\n",
    "train = np.array(train).reshape((-1, 1, 28, 28)).astype(np.uint8)\n",
    "test = np.array(test).reshape((-1, 1, 28, 28)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can actually plot those pixel color values and see what a sample picture of a digit looks like. Below is the picture of a digit in the 1729th row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11e66aad0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neIejRvj/FqRhPnSCysYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12feb75d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "plt.imshow(train[1729][0], cmap=cm.binary) # draw the picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Predict and Save\n",
    "Below is a simple NN set up. Supposedly, it should give >0.9 accuracy score. I had trouble with figuring out\n",
    "the training part in that the accuracy I was getting would not change during the training process. All I had to \n",
    "do was to decrease the learning rate from 0.01 to 0.0001, nota bene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import visualize\n",
    "\n",
    "net1 = NeuralNet(\n",
    "        layers=[('input', layers.InputLayer),\n",
    "                ('hidden', layers.DenseLayer),\n",
    "                ('output', layers.DenseLayer),\n",
    "                ],\n",
    "        # layer parameters:\n",
    "        input_shape=(None,1,28,28),\n",
    "        hidden_num_units=1000, # number of units in 'hidden' layer\n",
    "        output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "        output_num_units=10,  # 10 target values for the digits 0, 1, 2, ..., 9\n",
    "\n",
    "        # optimization method:\n",
    "        update=nesterov_momentum,\n",
    "        update_learning_rate=0.0001,\n",
    "        update_momentum=0.9,\n",
    "\n",
    "        max_epochs=15,\n",
    "        verbose=1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/nolearn/lasagne/base.py:428: UserWarning: The Param class is deprecated. Replace Param(default=N) by theano.In(value=N)\n",
      "  for input_layer in input_layers]\n",
      "//anaconda/lib/python2.7/site-packages/nolearn/lasagne/base.py:429: UserWarning: The Param class is deprecated. Replace Param(default=N) by theano.In(value=N)\n",
      "  inputs = X_inputs + [theano.Param(y_batch, name=\"y\")]\n",
      "WARNING (theano.gof.compilelock): Overriding existing lock by dead process '22719' (I am process '1421')\n",
      "WARNING:theano.gof.compilelock:Overriding existing lock by dead process '22719' (I am process '1421')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 795010 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name    size\n",
      "---  ------  -------\n",
      "  0  input   1x28x28\n",
      "  1  hidden  1000\n",
      "  2  output  10\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m6.96745\u001b[0m       \u001b[32m2.02490\u001b[0m      3.44089      0.92962  7.79s\n",
      "      2       \u001b[36m1.02433\u001b[0m       \u001b[32m1.51473\u001b[0m      0.67625      0.93720  8.10s\n",
      "      3       \u001b[36m0.45578\u001b[0m       \u001b[32m1.28252\u001b[0m      0.35538      0.93897  8.01s\n",
      "      4       \u001b[36m0.22336\u001b[0m       1.30088      0.17170      0.93696  7.89s\n",
      "      5       \u001b[36m0.12570\u001b[0m       \u001b[32m1.09203\u001b[0m      0.11511      0.94549  7.61s\n",
      "      6       \u001b[36m0.06349\u001b[0m       \u001b[32m1.02559\u001b[0m      0.06191      0.94838  7.61s\n",
      "      7       \u001b[36m0.03274\u001b[0m       \u001b[32m0.98421\u001b[0m      0.03326      0.95069  7.85s\n",
      "      8       \u001b[36m0.01843\u001b[0m       0.98769      0.01866      0.95117  8.19s\n",
      "      9       \u001b[36m0.01186\u001b[0m       1.02080      0.01162      0.94856  8.08s\n",
      "     10       \u001b[36m0.00547\u001b[0m       \u001b[32m0.97344\u001b[0m      0.00562      0.95200  7.91s\n",
      "     11       \u001b[36m0.00274\u001b[0m       \u001b[32m0.93464\u001b[0m      0.00293      0.95265  7.91s\n",
      "     12       \u001b[36m0.00128\u001b[0m       0.93472      0.00137      0.95146  8.20s\n",
      "     13       \u001b[36m0.00074\u001b[0m       \u001b[32m0.92624\u001b[0m      0.00079      0.95277  7.73s\n",
      "     14       \u001b[36m0.00034\u001b[0m       \u001b[32m0.92333\u001b[0m      0.00036      0.95288  7.60s\n",
      "     15       \u001b[36m0.00006\u001b[0m       0.92389      0.00006      0.95229  7.54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x1290a7fd0>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x1290a7f50>,\n",
       "     custom_score=None, hidden_num_units=1000,\n",
       "     input_shape=(None, 1, 28, 28),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('hidden', <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=15, more_params={},\n",
       "     objective=<function objective at 0x12909db90>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x128ec4de8>,\n",
       "     on_batch_finished=[],\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x1290a9ea8>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x1290be830>],\n",
       "     output_nonlinearity=<function softmax at 0x128d40de8>,\n",
       "     output_num_units=10, regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x1290b8050>,\n",
       "     update=<function nesterov_momentum at 0x128ece578>,\n",
       "     update_learning_rate=0.0001, update_momentum=0.9,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the network\n",
    "net1.fit(train, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the output associated with the training process. Right off the bat this set up gives us ~0.95 accuracy\n",
    "score in just 15 epochs which completes in less than 3 minutes. Unfortunately, one layer neural network does not improve \n",
    "beyond 0.96 accuracy score ragardless of how many neurons in a layer is specified (1000 in case above).\n",
    "\n",
    "I will try out the convolutional neural network. To set up the CNN I added two convolutional layers and one pooling layer. \n",
    "I would add another pooling layer and a dropout layer, but training such a model would last for over 20 minutes and kaggle notebook is only allowed to run for 1200 seconds (20 minutes). \n",
    "As a result, below is the CNN model I will use for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 1739428 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name     size\n",
      "---  -------  --------\n",
      "  0  input    1x28x28\n",
      "  1  conv1    7x26x26\n",
      "  2  pool1    7x13x13\n",
      "  3  conv2    12x12x12\n",
      "  4  hidden3  1000\n",
      "  5  output   10\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  ------\n",
      "      1       \u001b[36m2.22636\u001b[0m       \u001b[32m0.42536\u001b[0m      5.23401      0.86741  33.92s\n",
      "      2       \u001b[36m0.32667\u001b[0m       \u001b[32m0.28545\u001b[0m      1.14440      0.91032  33.75s\n",
      "      3       \u001b[36m0.23419\u001b[0m       \u001b[32m0.22900\u001b[0m      1.02265      0.92927  33.60s\n",
      "      4       \u001b[36m0.18815\u001b[0m       \u001b[32m0.19794\u001b[0m      0.95057      0.93945  33.28s\n",
      "      5       \u001b[36m0.15920\u001b[0m       \u001b[32m0.17785\u001b[0m      0.89513      0.94448  34.48s\n",
      "      6       \u001b[36m0.13858\u001b[0m       \u001b[32m0.16391\u001b[0m      0.84546      0.94945  34.36s\n",
      "      7       \u001b[36m0.12283\u001b[0m       \u001b[32m0.15354\u001b[0m      0.80000      0.95282  36.05s\n",
      "      8       \u001b[36m0.11021\u001b[0m       \u001b[32m0.14528\u001b[0m      0.75862      0.95519  37.92s\n",
      "      9       \u001b[36m0.09963\u001b[0m       \u001b[32m0.13846\u001b[0m      0.71954      0.95720  36.81s\n",
      "     10       \u001b[36m0.09055\u001b[0m       \u001b[32m0.13294\u001b[0m      0.68115      0.96016  37.24s\n",
      "     11       \u001b[36m0.08271\u001b[0m       \u001b[32m0.12847\u001b[0m      0.64378      0.96170  38.22s\n",
      "     12       \u001b[36m0.07582\u001b[0m       \u001b[32m0.12479\u001b[0m      0.60757      0.96229  39.59s\n",
      "     13       \u001b[36m0.06968\u001b[0m       \u001b[32m0.12155\u001b[0m      0.57321      0.96300  34.60s\n",
      "     14       \u001b[36m0.06416\u001b[0m       \u001b[32m0.11896\u001b[0m      0.53932      0.96395  35.40s\n",
      "     15       \u001b[36m0.05917\u001b[0m       \u001b[32m0.11668\u001b[0m      0.50710      0.96490  38.02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Koba/.ssh/src/lasagne/lasagne/layers/conv.py:489: UserWarning: The `image_shape` keyword argument to `tensor.nnet.conv2d` is deprecated, it has been renamed to `input_shape`.\n",
      "  border_mode=border_mode)\n"
     ]
    }
   ],
   "source": [
    "def CNN(n_epochs):\n",
    "    net1 = NeuralNet(\n",
    "        layers=[\n",
    "        ('input', layers.InputLayer),\n",
    "        ('conv1', layers.Conv2DLayer),      #Convolutional layer.  Params defined below\n",
    "        ('pool1', layers.MaxPool2DLayer),   # Like downsampling, for execution speed\n",
    "        ('conv2', layers.Conv2DLayer),\n",
    "        ('hidden3', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "\n",
    "    input_shape=(None, 1, 28, 28),\n",
    "    conv1_num_filters=7, \n",
    "    conv1_filter_size=(3, 3), \n",
    "    conv1_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        \n",
    "    pool1_pool_size=(2, 2),\n",
    "        \n",
    "    conv2_num_filters=12, \n",
    "    conv2_filter_size=(2, 2),    \n",
    "    conv2_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        \n",
    "    hidden3_num_units=1000,\n",
    "    output_num_units=10, \n",
    "    output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "\n",
    "    update_learning_rate=0.0001,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    max_epochs=n_epochs,\n",
    "    verbose=1,\n",
    "    )\n",
    "    return net1\n",
    "\n",
    "cnn = CNN(15).fit(train,target) # train the CNN model for 15 epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this CNN model produces a slightly better result than a simple NN model for the same number of epochs and neurons in the hidden layer. \n",
    "The CNN model was more time consuming though. If you think that it is not worth it to use the CNN model over the NN you are wrong.\n",
    "NN model like any other has an upper bound on the best accuracy score it can produce. After 20 epochs \n",
    "NN model does not improve beyond ~0.97 whereas a CNN model gets closer to one. I was able to break into\n",
    "top 100 and get the 94th place by using two convolutional layers and two pooling layers which gave me 0.98614 accuracy\n",
    "in about 5 hours. I will provide the code in the appendix.\n",
    "\n",
    "So there you go. You have a starting point for using neural nets for image classification. \n",
    "If you expand on the info here and reach a score greater than 0.99 please drop a comment.\n",
    "Now, lets use it on the test set and save the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use the NN model to classify test data\n",
    "pred = cnn.predict(test)\n",
    "\n",
    "# save results\n",
    "np.savetxt('submission_cnn.csv', np.c_[range(1,len(test)+1),pred], \\\n",
    "           delimiter=',', header = 'ImageId,Label', comments = '', fmt='%d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Python really stands out when it comes to solving data problems. Its quick, intuitive, well documented and has a big community.\n",
    "However, its biggest drawback in my opinion is setting up the environment. My set up is [Jupyter Notebook](http://jupyter.org/) coupled \n",
    "with [Anaconda](https://www.continuum.io/downloads). Both are great tools, however, I ended up spending \n",
    "couple hours taking care of the dependencies (theano and lasagne) and the Windows environment variables. In contrast to Mathematica which \n",
    "has superb report generating options, setting up Python environment can be and was for me a tiring experience. Nevertheless, it pays off because \n",
    "Python framework is well developed for solving data problems. For instance, Mathematica does not even have a CNN\n",
    "implementation available as of 11/4/2015 and everything is done under the hood whereas in a Python framework one \n",
    "can find almost any algorithm imaginable.\n",
    "\n",
    "Among Python, R and Julia I beleive Python and R are most competitive data science technologies with Julia being \n",
    "in the process of maturing. Choosing Python over R and vica versa really has to do with either individual preference or\n",
    "the suitability of the technology for the problem at hand. Python is more efficient than R. But Julia is more \n",
    "efficient than both Python and R.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources Used:\n",
    "\n",
    "[Convolutional Neural Networks (LeNet)](http://deeplearning.net/tutorial/lenet.html)\n",
    "\n",
    "[CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/convolutional-networks/)\n",
    "\n",
    "[Tutorial: Training convolutional neural networks with nolearn](http://nbviewer.ipython.org/github/dnouri/nolearn/blob/master/docs/notebooks/CNN_tutorial.ipynb)\n",
    "\n",
    "[Using convolutional neural nets to detect facial keypoints tutorial](http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/)\n",
    "\n",
    "[Deep learning â€“ Convolutional neural networks and feature extraction with Python](http://blog.christianperone.com/2015/08/convolutional-neural-networks-and-feature-extraction-with-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "## CNN that achieved 98.6% accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import visualize\n",
    "\n",
    "def main():\n",
    "    print(\"Loading in data\")\n",
    "    # create the training & test sets, skipping the header row with [1:]\n",
    "    dataset = pd.read_csv(\"train.csv\")\n",
    "    target = dataset[[0]].values.ravel()\n",
    "    train = dataset.iloc[:,1:].values\n",
    "    test = pd.read_csv(\"test.csv\").values\n",
    "\n",
    "    # convert to array, specify data type, and reshape\n",
    "    target = target.astype(np.uint8)\n",
    "    train = np.array(train).reshape((-1, 1, 28, 28)).astype(np.uint8)\n",
    "    test = np.array(test).reshape((-1, 1, 28, 28)).astype(np.uint8)\n",
    "    print(\"training model\")\n",
    "    # model set up\n",
    "    def CNN(n_epochs):\n",
    "        net1 = NeuralNet(\n",
    "            layers=[('input', layers.InputLayer),\n",
    "                ('conv2d1', layers.Conv2DLayer),\n",
    "                ('maxpool1', layers.MaxPool2DLayer),\n",
    "                ('conv2d2', layers.Conv2DLayer),\n",
    "                ('maxpool2', layers.MaxPool2DLayer),\n",
    "                ('dropout1', layers.DropoutLayer),\n",
    "                ('dense', layers.DenseLayer),\n",
    "                ('dropout2', layers.DropoutLayer),\n",
    "                ('output', layers.DenseLayer),\n",
    "                ],\n",
    "         # input layer\n",
    "         input_shape=(None, 1, 28, 28),\n",
    "         # layer conv2d1\n",
    "         conv2d1_num_filters=32,\n",
    "         conv2d1_filter_size=(5, 5),\n",
    "           conv2d1_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "         conv2d1_W=lasagne.init.GlorotUniform(),  \n",
    "         # layer maxpool1\n",
    "         maxpool1_pool_size=(2, 2),    \n",
    "         # layer conv2d2\n",
    "         conv2d2_num_filters=32,\n",
    "         conv2d2_filter_size=(5, 5),\n",
    "         conv2d2_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "         # layer maxpool2\n",
    "         maxpool2_pool_size=(2, 2),\n",
    "         # dropout1\n",
    "         dropout1_p=0.5,    \n",
    "         # dense\n",
    "         dense_num_units=5000,\n",
    "         dense_nonlinearity=lasagne.nonlinearities.rectify,    \n",
    "         # dropout2\n",
    "         dropout2_p=0.5,    \n",
    "         # output\n",
    "         output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "         output_num_units=10,\n",
    "         # optimization method params\n",
    "         update=nesterov_momentum,\n",
    "         update_learning_rate=0.0001,\n",
    "         update_momentum=0.9,\n",
    "         max_epochs=n_epochs,\n",
    "         verbose=1)\n",
    "\n",
    "        return net1\n",
    "\n",
    "    # train model\n",
    "    cnn = CNN(100).fit(train,target)\n",
    "\n",
    "    # use the CNN model to classify test data\n",
    "    pred = cnn.predict(test)\n",
    "\n",
    "    # save results\n",
    "    np.savetxt('submission_cnn.csv', np.c_[range(1,len(test)+1),pred], \\\n",
    "               delimiter=',', header = 'ImageId,Label', comments = '', fmt='%d')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
